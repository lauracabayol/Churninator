\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx}
% ref packages
\usepackage{nameref}
% folowing  must be in this order
\usepackage{varioref}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{listings}

\usepackage[utf8]{inputenc} 
\usepackage[a4paper,
            left=2cm,
            right=2cm,
            top=2cm,
            bottom=2cm]{geometry}

\usepackage[english]{babel}
\usepackage[skip=10pt plus2pt, indent=10pt]{parskip}
\begin{document}

\section{Introduction}
Churn prediction is a crucial task in customer relationship management, aiming to identify customers who are likely to discontinue using a service. Accurately predicting churn allows companies to take proactive measures to retain these customers. In this task, we address bank churn from costumers data using machine-learning techniques. 

\section{Data Description}
The dataset used for this task consists of both structured and unstructured data. It contains a total of 10,000 samples, where each sample represents a unique customer. The structured data includes features such as the number of products owned by the customer, their account balance, salary, age, gender, and other information. 

To prepare the data for analysis, we first need to encode the categorical features (such as age, gender, country, etc.) into numerical labels. This step is essential because most machine learning algorithms require numerical input. The encoding process transforms each unique category into an integer label. This encoding allows the structured data to be effectively utilized by machine learning models.

The following categorical features were encoded into integer labels:
\begin{itemize}
    \item[-] \textbf{Gender:} Encoded as 0 for female and 1 for male.
    \item[-] \textbf{Country:} Each country was assigned a unique integer label.
\end{itemize}
 
Customer feedback is a valuable source of unstructured data that can provide insights into customer satisfaction and potential churn risk. The next steps involve handling the unstructured data and integrating it with the structured data. We perform sentiment analysis to classify the feedback as positive or negative employing the BERT (Bidirectional Encoder Representations from Transformers) model. The first step is tokenization with the \texttt{BertTokenizer}. It is used to convert the text of each feedback into a format suitable for BERT. This involves breaking the text into tokens and mapping each token to an integer index in the BERT vocabulary. The tokenized text is then passed to the \texttt{BertForSequenceClassification module}. This module is fine-tuned to classify each piece of feedback into one of five categories, corresponding to star ratings ranging from 1 star (the poorest score) to 5 stars (the best score).

Once each feedback has been classified into a star rating, we encode these ratings into integer labels. We also included a derived variable from the sentiment analysis that indicates how certain BERT is in the classification of costumer's feedback. This variable can help mitigate the impact of errors from BERT's predictions.

Once the data is all preprocessed, with a format that algorithms can read, we can look at the correlation between different variables and the probability of customer churn. The right panel on Fig.~\ref{fig:class_distribution} shows the correlation between all features in the dataset and their current status (Exited/not Exited). It clearly indicates that customer feedback is an important feature in predicting churn. However, we also found instances where customers gave excellent ratings (5 stars) but still left the service. Manual verification confirmed the high ratings, suggesting that despite positive feedback, these customers decided to churn. Conversely, some customers gave poor ratings (1 or 2 stars) but did not leave the service. This indicates that negative feedback does not always lead to churn. These findings highlight the complexity of human behavior. While customer feedback is a relevant feature, it is not an infallible predictor of churn. Other factors, potentially unaccounted for in the dataset, may influence a customer's decision to leave or stay. 

Last, the dataset exhibits a significant class imbalance, which can affect the performance of machine learning models. Out of the 10,000 samples, 8,000 customers did not leave the service, while only 2,000 did. To illustrate the class imbalance, the left panel on Fig.\ref{fig:class_distribution} presents a histogram showing the distribution of the two classes.


\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/class_distribution.png}
    \includegraphics[width=0.45\textwidth]{figures/correlation_matrix.png}
    \caption{\emph{Left:} class distribution of the dataset. \emph{Right:} Correlation between the features in the dataset and the exited outcome}
    \label{fig:class_distribution}
\end{figure}

\section{Main Results}
To address the churn prediction task, we employed two machine learning approaches: Gradient Boosting and a Neural Network. Other algorithms were also tested, but Gradient Boosting provided the best results. Both algorithms were optimized using Optuna, a hyperparameter optimization framework. Optuna allows for efficient exploration of the hyperparameter space to find the best performing settings for each model.

The performance of the models was evaluated using two primary metrics:
\begin{itemize}
    \item \textbf{ROC Curve:} The Receiver Operating Characteristic (ROC) curve is a graphical representation of the true positive rate (sensitivity) versus the false positive rate (1-specificity) at various threshold settings. The area under the ROC curve (AUC) provides a single metric to evaluate the overall performance of the model, with higher values indicating better performance.
    \item \textbf{Confusion Matrix:} The confusion matrix provides a detailed breakdown of the model's predictions, showing the number of true positives, true negatives, false positives, and false negatives. This helps in understanding the model's performance on each class.
\end{itemize}

\subsection{Gradient Boosting Results}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/roc_curve_gb.png}
    \includegraphics[width=0.45\textwidth]{figures/confusion_matrix_gb.png}
    \caption{ROC Curve for Gradient Boosting}
    \label{fig:roc_curve_gb}
\end{figure}

The Gradient Boosting model achieved an AUC of 0.91 (left panel on Fig.\ref{fig:roc_curve_gb}). The confusion matrix (right panel on Fig.\ref{fig:roc_curve_gb}) indicated the following performance:
\begin{itemize}
    \item \textbf{True Negatives:} 95\% of the customers who did not leave the service were correctly predicted.
    \item \textbf{True Positives:} 70\% of the customers who left the service were correctly predicted.
\end{itemize}

\subsection{Neural Network Results}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.45\textwidth]{figures/roc_curve_nn.png}
    \includegraphics[width=0.45\textwidth]{figures/confusion_matrix_nn.png}
    \caption{ROC Curve for Neural Network}
    \label{fig:roc_curve_nn}
\end{figure}

The Neural Network model yielded similar results, though slightly worse:
\begin{itemize}
    \item \textbf{AUC:} Approximately 0.86 (left panel on Fig.\ref{fig:roc_curve_nn}).
    \item \textbf{True Negatives:} 90\% of the customers who did not leave the service were correctly predicted (right panel on Fig.\ref{fig:roc_curve_nn})
    \item \textbf{True Positives:} 65\% of the customers who left the service were correctly predicted.
\end{itemize}

The slightly lower performance of the Neural Network could be attributed to its sensitivity to dummy variables and the need for data normalization. Although normalization was performed, further optimization might improve results.

\subsection{Discussion on Prediction Imperfection}

Despite the overall performance of the models, churn prediction is not perfect. One significant challenge is the inherent unpredictability of human behavior. As previously noted, some customers with excellent feedback ratings still chose to leave the service, while others with poor ratings decided to stay. This unpredictability introduces complexity that machine learning models may not fully capture.

Another factor contributing to the imperfection is the class imbalance in the dataset. Although methods like under-sampling, over-sampling, and bias adjustment for the neural network were applied to mitigate this issue, these techniques did not lead to a substantial improvement in the model's performance. 

To enhance the accuracy and robustness of churn prediction, several avenues for future work are suggested:
\begin{itemize}
    \item \textbf{Ensemble Methods:} Exploring ensemble methods that combine predictions from multiple models could potentially improve performance (bagging, boosting, and stacking).
    \item \textbf{Advanced Imbalance Handling:} Further investigation into advanced techniques for handling imbalanced data is warranted. This could include advanced cost-sensitive learning approaches.
\end{itemize}

\end{document}